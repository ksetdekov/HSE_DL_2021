{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "RNNs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOOLQMEgt6KJ"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/NktBkzn/HSE_DL_2021/blob/master/12_week/RNNs.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nje_LngItrLy"
      },
      "source": [
        "- Ноутбук заимствован с курса [dlcourse.ai](https://dlcourse.ai)\n",
        "- Решение ноутбука взято [отсюда](https://github.com/omega1996/dlcourse/blob/master/assignments/assignment6/RNNs.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiPbD_lTXUMd"
      },
      "source": [
        "# Задание 6: Рекуррентные нейронные сети (RNNs)\n",
        "\n",
        "Это задание адаптиповано из Deep NLP Course at ABBYY (https://github.com/DanAnastasyev/DeepNLP-Course) с разрешения автора - Даниила Анастасьева. Спасибо ему огромное!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P59NYU98GCb9",
        "outputId": "4490de6c-f3d4-4d76-9838-54fbcff75e2c"
      },
      "source": [
        "!pip install gensim==4.1.2\n",
        "!pip install nltk==3.6.3\n",
        "!pip install scikit-learn==1.0.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim==4.1.2\n",
            "  Downloading gensim-4.1.2-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.7/dist-packages (from gensim==4.1.2) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.1.2) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==4.1.2) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.1.2\n",
            "Collecting nltk==3.6.3\n",
            "  Downloading nltk-3.6.3-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 13.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.3) (1.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.3) (2019.12.20)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.3) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.6.3) (4.62.3)\n",
            "Installing collected packages: nltk\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.6.3\n",
            "Requirement already satisfied: scikit-learn==1.0.1 in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==1.0.1) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1TvJm34-fd5_",
        "outputId": "81928b78-445f-4b6a-96d7-307f3f69d300"
      },
      "source": [
        "import nltk\n",
        "nltk.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3.6.3'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sVtGHmA9aBM"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    from torch.cuda import FloatTensor, LongTensor\n",
        "else:\n",
        "    from torch import FloatTensor, LongTensor\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6CNKM3b4hT1"
      },
      "source": [
        "# Рекуррентные нейронные сети (RNNs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_XkoGNQUeGm"
      },
      "source": [
        "## POS Tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFEtWrS_4rUs"
      },
      "source": [
        "Мы рассмотрим применение рекуррентных сетей к задаче sequence labeling (последняя картинка).\n",
        "\n",
        "![RNN types](http://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "*From [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)*\n",
        "\n",
        "Самые популярные примеры для такой постановки задачи - Part-of-Speech Tagging и Named Entity Recognition.\n",
        "\n",
        "Мы порешаем сейчас POS Tagging для английского.\n",
        "\n",
        "Будем работать с таким набором тегов:\n",
        "- ADJ - adjective (new, good, high, ...)\n",
        "- ADP - adposition (on, of, at, ...)\n",
        "- ADV - adverb (really, already, still, ...)\n",
        "- CONJ - conjunction (and, or, but, ...)\n",
        "- DET - determiner, article (the, a, some, ...)\n",
        "- NOUN - noun (year, home, costs, ...)\n",
        "- NUM - numeral (twenty-four, fourth, 1991, ...)\n",
        "- PRT - particle (at, on, out, ...)\n",
        "- PRON - pronoun (he, their, her, ...)\n",
        "- VERB - verb (is, say, told, ...)\n",
        "- . - punctuation marks (. , ;)\n",
        "- X - other (ersatz, esprit, dunno, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPIkKdFlHB-X"
      },
      "source": [
        "Скачаем данные:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiA2dGmgF1rW",
        "outputId": "8843d1b3-2076-4186-f2f9-7ae59a373799"
      },
      "source": [
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "nltk.download('brown')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "data = nltk.corpus.brown.tagged_sents(tagset='universal')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTNDocatrWAv",
        "outputId": "e8669b78-55e7-4283-80e1-cc89519b43b9"
      },
      "source": [
        "len(data), len(data[0]), len(data[1])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(57340, 25, 43)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d93g_swyJA_V"
      },
      "source": [
        "Пример размеченного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QstS4NO0L97c",
        "outputId": "5f11fdd6-f5b4-4d80-d0ae-ec891daaadd9"
      },
      "source": [
        "for word, tag in data[0]:\n",
        "    print('{:15}\\t{}'.format(word, tag))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The            \tDET\n",
            "Fulton         \tNOUN\n",
            "County         \tNOUN\n",
            "Grand          \tADJ\n",
            "Jury           \tNOUN\n",
            "said           \tVERB\n",
            "Friday         \tNOUN\n",
            "an             \tDET\n",
            "investigation  \tNOUN\n",
            "of             \tADP\n",
            "Atlanta's      \tNOUN\n",
            "recent         \tADJ\n",
            "primary        \tNOUN\n",
            "election       \tNOUN\n",
            "produced       \tVERB\n",
            "``             \t.\n",
            "no             \tDET\n",
            "evidence       \tNOUN\n",
            "''             \t.\n",
            "that           \tADP\n",
            "any            \tDET\n",
            "irregularities \tNOUN\n",
            "took           \tVERB\n",
            "place          \tNOUN\n",
            ".              \t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epdW8u_YXcAv"
      },
      "source": [
        "Построим разбиение на train/val/test - наконец-то, всё как у нормальных людей.\n",
        "\n",
        "На train будем учиться, по val - подбирать параметры и делать всякие early stopping, а на test - принимать модель по ее финальному качеству."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTai8Ta0lgwL",
        "outputId": "93fa1ec8-ab03-46bf-c7a4-d33819c606fe"
      },
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.25, random_state=42)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "print('Words count in train set:', sum(len(sent) for sent in train_data))\n",
        "print('Words count in val set:', sum(len(sent) for sent in val_data))\n",
        "print('Words count in test set:', sum(len(sent) for sent in test_data))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words count in train set: 739769\n",
            "Words count in val set: 130954\n",
            "Words count in test set: 290469\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eChdLNGtXyP0"
      },
      "source": [
        "Построим маппинги из слов в индекс и из тега в индекс:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCjwwDs6Zq9x",
        "outputId": "df7e014b-3817-4f32-f2b4-23bbd67e4c41"
      },
      "source": [
        "words = {word for sample in train_data for word, tag in sample}\n",
        "word2ind = {word: ind + 1 for ind, word in enumerate(words)}  # ind + 1 to leave 0 idx blank for <pad>\n",
        "word2ind['<pad>'] = 0\n",
        "\n",
        "tags = {tag for sample in train_data for word, tag in sample}\n",
        "tag2ind = {tag: ind + 1 for ind, tag in enumerate(tags)}\n",
        "tag2ind['<pad>'] = 0\n",
        "\n",
        "print('Unique words in train = {}. Tags = {}'.format(len(word2ind), tags))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words in train = 45441. Tags = {'CONJ', 'PRON', 'VERB', 'ADJ', 'PRT', 'NUM', '.', 'NOUN', 'ADP', 'ADV', 'DET', 'X'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nGShrtNr59m"
      },
      "source": [
        "word2ind"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "URC1B2nvPGFt",
        "outputId": "36833855-9a87-47ed-b2e2-7fdd67ec2413"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "tag_distribution = Counter(tag for sample in train_data for _, tag in sample)\n",
        "tag_distribution = [tag_distribution[tag] for tag in tags]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "bar_width = 0.35\n",
        "plt.bar(np.arange(len(tags)), tag_distribution, bar_width, align='center', alpha=0.5)\n",
        "plt.xticks(np.arange(len(tags)), tags)\n",
        "    \n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gArQwbzWWkgi"
      },
      "source": [
        "## Бейзлайн\n",
        "\n",
        "Какой самый простой теггер можно придумать? Давайте просто запоминать, какие теги самые вероятные для слова (или для последовательности):\n",
        "\n",
        "![tag-context](https://www.nltk.org/images/tag-context.png)  \n",
        "*From [Categorizing and Tagging Words, nltk](https://www.nltk.org/book/ch05.html)*\n",
        "\n",
        "На картинке показано, что для предсказания $t_n$ используются два предыдущих предсказанных тега + текущее слово. По корпусу считаются вероятность для $P(t_n| w_n, t_{n-1}, t_{n-2})$, выбирается тег с максимальной вероятностью.\n",
        "\n",
        "Более аккуратно такая идея реализована в Hidden Markov Models: по тренировочному корпусу вычисляются вероятности $P(w_n| t_n), P(t_n|t_{n-1}, t_{n-2})$ и максимизируется их произведение.\n",
        "\n",
        "Простейший вариант - униграммная модель, учитывающая только слово:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MergdmlUcDDz"
      },
      "source": [
        "На вход UnigramTagger принимает данные в таком формате:\\\n",
        "*train (list(list(tuple(str, str)))) – The corpus of training data, a list of tagged sentences*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jihL_L1EcwzV",
        "outputId": "600dc6e5-9a99-4340-889f-3c3cbfb31fff"
      },
      "source": [
        "test_data[:2]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('Open', 'ADJ'), ('market', 'NOUN'), ('policy', 'NOUN')],\n",
              " [('And', 'CONJ'),\n",
              "  ('you', 'PRON'),\n",
              "  ('think', 'VERB'),\n",
              "  ('you', 'PRON'),\n",
              "  ('have', 'VERB'),\n",
              "  ('language', 'NOUN'),\n",
              "  ('problems', 'NOUN'),\n",
              "  ('.', '.')]]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rWmSToIaeAo",
        "outputId": "4fbc35e9-4661-4bfa-8d00-590167cc8a9b"
      },
      "source": [
        "import nltk\n",
        "\n",
        "default_tagger = nltk.DefaultTagger('NN')  # tags every word witn a noun\n",
        "\n",
        "# The UnigramTagger finds the most likely tag for each word in a training corpus, \n",
        "# and then uses that information to assign tags to new tokens.\n",
        "unigram_tagger = nltk.UnigramTagger(train_data, backoff=default_tagger)\n",
        "print('Accuracy of unigram tagger = {:.2%}'.format(unigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of unigram tagger = 92.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GocIMguUeNKq"
      },
      "source": [
        "Хорошая [заметка](https://stackoverflow.com/questions/46713629/evaluating-pos-tagger-in-nltk) на SO про синтаксис Taggers из nltk\n",
        "\n",
        "Выжимка:\n",
        "```python\n",
        "tagged_sentences = brown.tagged_sents(categories=\"news\", tagset=\"universal\")\n",
        "\n",
        "# let's keep 20% of the data for testing, and 80 for training\n",
        "i = int(len(tagged_sentences)*0.2)\n",
        "train_sentences = tagged_sentences[i:]\n",
        "test_sentences = tagged_sentences[:i]\n",
        "\n",
        "# train\n",
        "unigram_tagger = UnigramTagger(train_sentences)\n",
        "# get ACCURACY; default evaluation metric for nltk taggers is accuracy\n",
        "accuracy = unigram_tagger.evaluate(test_sentences)\n",
        "\n",
        "tagged_test_sentences = unigram_tagger.tag_sents([[token for token,tag in sent] for sent in test_sentences])  # words(tokens) only\n",
        "pred = [str(tag) for sentence in tagged_test_sentences for token,tag in sentence]  # predicted tags\n",
        "gold = [str(tag) for sentence in test_sentences for token,tag in sentence]  # true tags\n",
        "\n",
        "from sklearn import metrics\n",
        "print(metrics.classification_report(gold, pred))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07Ymb_MkbWsF"
      },
      "source": [
        "Добавим вероятности переходов:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjz_Rk0bbMyH",
        "outputId": "ec158140-775d-4796-8ee1-73a782dd82da"
      },
      "source": [
        "# A tagger that chooses a token’s tag based its word string and on the preceding \n",
        "# words’ tag. In particular, a tuple consisting of the previous tag and \n",
        "# the word is looked up in a table, and the corresponding tag is returned.\n",
        "bigram_tagger = nltk.BigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of bigram tagger = {:.2%}'.format(bigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of bigram tagger = 93.42%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWMw6QHvbaDd"
      },
      "source": [
        "Обратите внимание, что `backoff` важен:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XCuxEBVbOY_",
        "outputId": "9bae0058-f819-492d-d2f7-2eff9712a47b"
      },
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of trigram tagger = 23.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRbIzTcOuSQj",
        "outputId": "85d864d9-5952-40ad-f9ff-fd80b1dd163c"
      },
      "source": [
        "trigram_tagger = nltk.TrigramTagger(train_data, backoff=unigram_tagger)\n",
        "print('Accuracy of trigram tagger = {:.2%}'.format(trigram_tagger.evaluate(test_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of trigram tagger = 93.28%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t3xyYd__8d-"
      },
      "source": [
        "## Увеличиваем контекст с рекуррентными сетями\n",
        "\n",
        "Униграмная модель работает на удивление хорошо, но мы же собрались учить сеточки.\n",
        "\n",
        "Омонимия - основная причина, почему униграмная модель плоха:  \n",
        "*“he cashed a check at the **bank**”*  \n",
        "vs  \n",
        "*“he sat on the **bank** of the river”*\n",
        "\n",
        "Поэтому нам очень полезно учитывать контекст при предсказании тега.\n",
        "\n",
        "Воспользуемся LSTM - он умеет работать с контекстом очень даже хорошо:\n",
        "\n",
        "![](https://image.ibb.co/kgmoff/Baseline-Tagger.png)\n",
        "\n",
        "Синим показано выделение фичей из слова, LSTM оранжевенький - он строит эмбеддинги слов с учетом контекста, а дальше зелененькая логистическая регрессия делает предсказания тегов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtRbz1SwgEqc"
      },
      "source": [
        "def convert_data(data, word2ind, tag2ind):\n",
        "    X = [[word2ind.get(word, 0) for word, _ in sample] for sample in data]\n",
        "    y = [[tag2ind[tag] for _, tag in sample] for sample in data]\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = convert_data(train_data, word2ind, tag2ind)\n",
        "X_val, y_val = convert_data(val_data, word2ind, tag2ind)\n",
        "X_test, y_test = convert_data(test_data, word2ind, tag2ind)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkGLzl2OuhBk",
        "outputId": "034cb255-3bce-4c7b-da33-a03330ca1bec"
      },
      "source": [
        "len(X_train), len(train_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36554, 36554)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhsTKZalfih6"
      },
      "source": [
        "def iterate_batches(data, batch_size):\n",
        "    X, y = data\n",
        "    n_samples = len(X)\n",
        "    print('n_samples', n_samples)\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "    for start in range(0, n_samples, batch_size):\n",
        "        end = min(start + batch_size, n_samples)\n",
        "        \n",
        "        batch_indices = indices[start:end]\n",
        "        print('batch_indices', batch_indices)\n",
        "        max_sent_len = max(len(X[ind]) for ind in batch_indices)\n",
        "        print('max_sent_len', max_sent_len)\n",
        "        X_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        y_batch = np.zeros((max_sent_len, len(batch_indices)))\n",
        "        \n",
        "        for batch_ind, sample_ind in enumerate(batch_indices):\n",
        "            X_batch[:len(X[sample_ind]), batch_ind] = X[sample_ind]\n",
        "            y_batch[:len(y[sample_ind]), batch_ind] = y[sample_ind]\n",
        "            \n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a2BLQIzwfAJ",
        "outputId": "994d6970-4d03-4e72-9d29-8b5c0baa1a10"
      },
      "source": [
        "len(X_train), len(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36554, 36554)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4XsRII5kW5x",
        "outputId": "29ff1f7e-6fb6-4ec7-ccd2-467e5618fffc"
      },
      "source": [
        "X_batch, y_batch = next(iterate_batches((X_train, y_train), 4))\n",
        "\n",
        "X_batch.shape, y_batch.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples 36554\n",
            "batch_indices [36344 22311 19437 32328]\n",
            "max_sent_len 24\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((24, 4), (24, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rY18rkng_c3",
        "outputId": "5f8168b1-b867-44e3-cff7-a15fc6e613ce"
      },
      "source": [
        "print(X_batch[:2])\n",
        "\n",
        "print(y_batch[:2])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[27869. 34048. 23458.  8526.]\n",
            " [23656. 12429. 34678. 41260.]]\n",
            "[[ 6.  8.  9.  5.]\n",
            " [ 8.  8. 11.  3.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5I9E9P6eFYv"
      },
      "source": [
        "**Задание** Реализуйте `LSTMTagger`:\n",
        "\n",
        "* [nn.Embedding](https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html)\n",
        "    - Input: (∗)\n",
        "    - Output: (∗, H)\n",
        "* [nn.LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n",
        "    - Input: (N, L, H_in)\n",
        "    - Output: (N, L, D * H_out), (h_n, c_n)\\\n",
        "    D = 2 if bidirectional=True otherwise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAr7DIjN616j"
      },
      "source": [
        "$L\\times bs \\xrightarrow{\\text{nn.Embedding}} L \\times bs \\times H_{in} \\xrightarrow{\\text{nn.LSTM}} L \\times bs \\times H^*_{out}\\xrightarrow{\\text{nn.Linear}} L \\times bs \\times \\text{tagset_size}$ \n",
        "\n",
        "\\*$H_{out}$ = lstm_hidden_dim\n",
        "\n",
        "- L - sequence length\n",
        "- bs - batch size\n",
        "- $H_{in}$ - number of input features representing an object\n",
        "- $H_{out}$ - number of output features representing an object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVEHju54d68T"
      },
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._emb = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self._lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count)\n",
        "        self._out_layer = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        emb = self._emb(inputs)\n",
        "        # print('emb shape:', emb.shape)\n",
        "        output, _ = self._lstm(emb)\n",
        "        out = self._out_layer(output)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_HA8zyheYGH"
      },
      "source": [
        "**Задание** Научитесь считать accuracy и loss (а заодно проверьте, что модель работает)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbrxsZ2mehWB",
        "outputId": "d695380d-32fb-4cf7-8228-a9859645e5b7"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ")\n",
        "\n",
        "X_batch, y_batch = torch.LongTensor(X_batch), torch.LongTensor(y_batch)\n",
        "\n",
        "logits = model(X_batch)\n",
        "preds = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# accuracy\n",
        "mask = (y_batch != 0).float() # помним, что тэг 0 соотвествует слову <pad>, не учитываем <pad> в рассчете точности\n",
        "correct_count = ((preds == y_batch).float() * mask).sum().item()\n",
        "total_count = mask.sum().item()\n",
        "\n",
        "print(f'Accuracy: {correct_count / total_count:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.0870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3_DgaXv3EZS",
        "outputId": "523b2667-5e1c-4ac0-f6e1-95ceebf35e31"
      },
      "source": [
        "print(X_batch.shape, logits.shape, preds.shape)\n",
        "# 32x4 ->(embed) 32x4x100 ->(lstm) 32x4x128 ->(linear) 32x4x13\n",
        "preds[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 4]) torch.Size([32, 4, 13]) torch.Size([32, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1,  2, 10,  2],\n",
              "        [ 0, 11,  0,  2]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9B4nuFy9d-C",
        "outputId": "a68a2e94-0297-45ce-a249-d1894a972cbe"
      },
      "source": [
        "print(y_batch.shape)\n",
        "y_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4,  8, 11,  3],\n",
              "        [ 8,  8,  7,  8],\n",
              "        [ 7,  1,  8, 11],\n",
              "        [ 3,  9,  6, 12],\n",
              "        [ 8, 11,  7,  1],\n",
              "        [ 1,  8,  8,  3],\n",
              "        [ 3,  4,  1,  8],\n",
              "        [ 8,  4,  8, 12],\n",
              "        [ 7,  7, 11, 10],\n",
              "        [ 8,  3,  3, 11],\n",
              "        [ 1, 11,  8,  1],\n",
              "        [ 9,  8,  7, 10],\n",
              "        [11,  1,  3,  5],\n",
              "        [ 1, 11, 12, 11],\n",
              "        [ 0,  2,  8,  6],\n",
              "        [ 0,  6,  1, 11],\n",
              "        [ 0, 12,  3,  5],\n",
              "        [ 0,  7,  8, 11],\n",
              "        [ 0,  3,  7, 12],\n",
              "        [ 0,  8,  3,  8],\n",
              "        [ 0,  7,  3,  7],\n",
              "        [ 0,  8,  8,  9],\n",
              "        [ 0,  1, 11,  1],\n",
              "        [ 0,  0, 11,  0],\n",
              "        [ 0,  0, 11,  0],\n",
              "        [ 0,  0, 11,  0],\n",
              "        [ 0,  0,  9,  0],\n",
              "        [ 0,  0,  6,  0],\n",
              "        [ 0,  0,  3,  0],\n",
              "        [ 0,  0, 12,  0],\n",
              "        [ 0,  0,  8,  0],\n",
              "        [ 0,  0,  1,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnFo9lilTw52"
      },
      "source": [
        "[nn.CrossEnropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html?highlight=ignore_index)\n",
        "\n",
        "$LogLoss = -\\sum_{i=1}^{C} t_i log(p_i)$\n",
        "\n",
        "$\\ell(x, y)=L=\\left\\{l_{1}, \\ldots, l_{N}\\right\\}^{\\top}, \\quad l_{n}=-w_{y_{n}} \\log \\dfrac{\\exp \\left(x_{n, y_{n}}\\right)}{\\sum_{c=1}^{C} \\exp \\left(x_{n, c}\\right)} \\cdot 1\\left\\{y_{n} \\neq\\right. \\text { ignore_index }$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMUyUm1hgpe3",
        "outputId": "fa42f621-720b-43e8-f71d-9b54a26c3dc3"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "logits = model(X_batch)\n",
        "loss = 0\n",
        "for ind, row in enumerate(logits):\n",
        "    loss += criterion(row, y_batch[ind])  # Input: (N, C) & (N) where C - classes #\n",
        "print(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(81.8602, grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSgV3NPUpcjH"
      },
      "source": [
        "**Задание** Вставьте эти вычисление в функцию:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FprPQ0gllo7b"
      },
      "source": [
        "import math\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def do_epoch(model, criterion, data, batch_size, optimizer=None, name=None):\n",
        "    epoch_loss = 0\n",
        "    correct_count = 0\n",
        "    sum_count = 0\n",
        "    \n",
        "    is_train = not optimizer is None\n",
        "    name = name or ''\n",
        "    model.train(is_train)\n",
        "    \n",
        "    batches_count = math.ceil(len(data[0]) / batch_size)\n",
        "    \n",
        "    with torch.autograd.set_grad_enabled(is_train):\n",
        "        with tqdm(total=batches_count) as progress_bar:\n",
        "            for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "                X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "                logits = model(X_batch)\n",
        "\n",
        "                loss = 0\n",
        "                for ind, row in enumerate(logits):\n",
        "                    loss += criterion(row, y_batch[ind])\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "\n",
        "                if optimizer:\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                preds = torch.argmax(logits, dim=-1)\n",
        "                mask = (y_batch != 0).float()\n",
        "                \n",
        "                cur_correct_count, cur_sum_count = ((preds == y_batch).float() * mask).sum().item(), mask.sum().item()\n",
        "\n",
        "                correct_count += cur_correct_count\n",
        "                sum_count += cur_sum_count\n",
        "\n",
        "                progress_bar.update()\n",
        "                progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                    name, loss.item(), cur_correct_count / cur_sum_count)\n",
        "                )\n",
        "                \n",
        "            progress_bar.set_description('{:>5s} Loss = {:.5f}, Accuracy = {:.2%}'.format(\n",
        "                name, epoch_loss / batches_count, correct_count / sum_count)\n",
        "            )\n",
        "\n",
        "    return epoch_loss / batches_count, correct_count / sum_count\n",
        "\n",
        "\n",
        "def fit(model, criterion, optimizer, train_data, epochs_count=1, batch_size=32,\n",
        "        val_data=None, val_batch_size=None):\n",
        "        \n",
        "    if not val_data is None and val_batch_size is None:\n",
        "        val_batch_size = batch_size\n",
        "        \n",
        "    for epoch in range(epochs_count):\n",
        "        name_prefix = '[{} / {}] '.format(epoch + 1, epochs_count)\n",
        "        train_loss, train_acc = do_epoch(model, criterion, train_data, batch_size, optimizer, name_prefix + 'Train:')\n",
        "        \n",
        "        if not val_data is None:\n",
        "            val_loss, val_acc = do_epoch(model, criterion, val_data, val_batch_size, None, name_prefix + '  Val:')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqfbeh1ltEYa",
        "outputId": "7a51b5a7-672c-46ef-d4b0-7f8158975996"
      },
      "source": [
        "model = LSTMTagger(\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0).cuda()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=5,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 5] Train: Loss = 48.91086, Accuracy = 73.78%: 100%|██████████| 572/572 [00:18<00:00, 31.50it/s]\n",
            "[1 / 5]   Val: Loss = 44.73542, Accuracy = 84.32%: 100%|██████████| 13/13 [00:00<00:00, 31.23it/s]\n",
            "[2 / 5] Train: Loss = 23.23695, Accuracy = 87.33%: 100%|██████████| 572/572 [00:17<00:00, 33.40it/s]\n",
            "[2 / 5]   Val: Loss = 30.08324, Accuracy = 89.40%: 100%|██████████| 13/13 [00:00<00:00, 32.50it/s]\n",
            "[3 / 5] Train: Loss = 15.91083, Accuracy = 91.31%: 100%|██████████| 572/572 [00:17<00:00, 33.40it/s]\n",
            "[3 / 5]   Val: Loss = 22.88544, Accuracy = 92.01%: 100%|██████████| 13/13 [00:00<00:00, 32.51it/s]\n",
            "[4 / 5] Train: Loss = 11.63074, Accuracy = 93.44%: 100%|██████████| 572/572 [00:17<00:00, 32.76it/s]\n",
            "[4 / 5]   Val: Loss = 20.85534, Accuracy = 93.14%: 100%|██████████| 13/13 [00:00<00:00, 29.96it/s]\n",
            "[5 / 5] Train: Loss = 8.83634, Accuracy = 94.74%: 100%|██████████| 572/572 [00:17<00:00, 31.86it/s]\n",
            "[5 / 5]   Val: Loss = 16.73591, Accuracy = 94.02%: 100%|██████████| 13/13 [00:00<00:00, 31.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0qGetIhfUE5"
      },
      "source": [
        "### Masking\n",
        "\n",
        "**Задание** Проверьте себя - не считаете ли вы потери и accuracy на паддингах - очень легко получить высокое качество за счет этого.\n",
        "\n",
        "У функции потерь есть параметр `ignore_index`, для таких целей. Для accuracy нужно использовать маскинг - умножение на маску из нулей и единиц, где нули на позициях паддингов (а потом усреднение по ненулевым позициям в маске)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAfV2dEOfHo5"
      },
      "source": [
        "**Задание** Посчитайте качество модели на тесте. Ожидается результат лучше бейзлайна!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98wr38_rw55D",
        "outputId": "76f0d1d3-5c88-49d1-e593-bfb0d65e79b2"
      },
      "source": [
        "def compute_accuracy(model, data, batch_size=64):\n",
        "    model.eval()\n",
        "    val_accuracy = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (X_batch, y_batch) in enumerate(iterate_batches(data, batch_size)):\n",
        "        X_batch, y_batch = LongTensor(X_batch), LongTensor(y_batch)\n",
        "        logits = model(X_batch)\n",
        "        \n",
        "        pred = torch.argmax(logits, dim=-1)\n",
        "        mask = (y_batch != 0).float()\n",
        "        \n",
        "        correct += ((pred == y_batch).float() * mask).sum().item()\n",
        "        \n",
        "        total += mask.sum().item()        \n",
        "        \n",
        "    val_accuracy = float(correct)/total\n",
        "        \n",
        "    return val_accuracy\n",
        "\n",
        "test_ac =  compute_accuracy(model, (X_test, y_test))\n",
        "print(f'Test accuracy is {test_ac:.2%}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is 94.02%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXUTSFaEHbDG"
      },
      "source": [
        "### Bidirectional LSTM\n",
        "\n",
        "Благодаря BiLSTM можно использовать сразу оба контеста при предсказании тега слова. Т.е. для каждого токена $w_i$ forward LSTM будет выдавать представление $\\mathbf{f_i} \\sim (w_1, \\ldots, w_i)$ - построенное по всему левому контексту - и $\\mathbf{b_i} \\sim (w_n, \\ldots, w_i)$ - представление правого контекста. Их конкатенация автоматически захватит весь доступный контекст слова: $\\mathbf{h_i} = [\\mathbf{f_i}, \\mathbf{b_i}] \\sim (w_1, \\ldots, w_n)$.\n",
        "\n",
        "![BiLSTM](https://www.researchgate.net/profile/Wang_Ling/publication/280912217/figure/fig2/AS:391505383575555@1470353565299/Illustration-of-our-neural-network-for-POS-tagging.png)  \n",
        "*From [Finding Function in Form: Compositional Character Models for Open Vocabulary Word Representation](https://arxiv.org/abs/1508.02096)*\n",
        "\n",
        "**Задание** Добавьте Bidirectional LSTM.\n",
        "\n",
        "Вспомним, что Unidirectional LSTM выглядела так:\n",
        "```python\n",
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._emb = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self._lstm = nn.LSTM(word_emb_dim, lstm_hidden_dim, num_layers=lstm_layers_count)\n",
        "        self._out_layer = nn.Linear(lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        emb = self._emb(inputs)\n",
        "        # print('emb shape:', emb.shape)\n",
        "        output, _ = self._lstm(emb)\n",
        "        out = self._out_layer(output)\n",
        "        return out\n",
        "```\n",
        "\n",
        "$L\\times bs \\xrightarrow{\\text{nn.Embedding}} L \\times bs \\times H_{in} \\xrightarrow{\\text{nn.LSTM}} L \\times bs \\times D\\cdot H_{out}\\xrightarrow{\\text{nn.Linear}} L \\times bs \\times \\text{tagset_size}$ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lWBE0sYXUMz"
      },
      "source": [
        "class BidirectionalLSTMTagger(nn.Module):\n",
        "    def __init__(self, vocab_size, tagset_size, word_emb_dim=100, lstm_hidden_dim=128, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._emb = nn.Embedding(vocab_size, word_emb_dim)\n",
        "        self._lstm = nn.LSTM(word_emb_dim, \n",
        "                             lstm_hidden_dim, \n",
        "                             num_layers=lstm_layers_count,\n",
        "                             bidirectional = True)\n",
        "        self._out_layer = nn.Linear(2*lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        emb = self._emb(inputs)\n",
        "        output, _ = self._lstm(emb)\n",
        "        out = self._out_layer(output)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qB8o9Dx3hJ_u",
        "outputId": "036c7457-55bc-4ca9-eff5-8a81b95a60b0"
      },
      "source": [
        "model = BidirectionalLSTMTagger(\n",
        "    lstm_layers_count=2,\n",
        "    vocab_size=len(word2ind),\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = 0).cuda()\n",
        "optimizer = optim.Adam(model.parameters(), lr = 5e-3, weight_decay = 5e-4)\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), \n",
        "    epochs_count=6, batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 6] Train: Loss = 21.08800, Accuracy = 88.51%: 100%|██████████| 572/572 [00:25<00:00, 22.03it/s]\n",
            "[1 / 6]   Val: Loss = 17.80767, Accuracy = 94.38%: 100%|██████████| 13/13 [00:00<00:00, 16.89it/s]\n",
            "[2 / 6] Train: Loss = 6.36271, Accuracy = 96.45%: 100%|██████████| 572/572 [00:25<00:00, 22.22it/s]\n",
            "[2 / 6]   Val: Loss = 17.89357, Accuracy = 94.84%: 100%|██████████| 13/13 [00:00<00:00, 17.97it/s]\n",
            "[3 / 6] Train: Loss = 3.90675, Accuracy = 97.51%: 100%|██████████| 572/572 [00:25<00:00, 22.19it/s]\n",
            "[3 / 6]   Val: Loss = 18.95265, Accuracy = 95.23%: 100%|██████████| 13/13 [00:00<00:00, 17.73it/s]\n",
            "[4 / 6] Train: Loss = 3.29084, Accuracy = 97.83%: 100%|██████████| 572/572 [00:25<00:00, 22.08it/s]\n",
            "[4 / 6]   Val: Loss = 18.86710, Accuracy = 95.24%: 100%|██████████| 13/13 [00:00<00:00, 17.25it/s]\n",
            "[5 / 6] Train: Loss = 3.09439, Accuracy = 97.96%: 100%|██████████| 572/572 [00:25<00:00, 22.06it/s]\n",
            "[5 / 6]   Val: Loss = 17.52249, Accuracy = 95.42%: 100%|██████████| 13/13 [00:00<00:00, 16.34it/s]\n",
            "[6 / 6] Train: Loss = 2.74650, Accuracy = 98.16%: 100%|██████████| 572/572 [00:25<00:00, 22.04it/s]\n",
            "[6 / 6]   Val: Loss = 17.15901, Accuracy = 95.29%: 100%|██████████| 13/13 [00:00<00:00, 17.63it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTXmYGD_ANhm"
      },
      "source": [
        "### Предобученные эмбеддинги\n",
        "\n",
        "Мы знаем, какая клёвая вещь - предобученные эмбеддинги. При текущем размере обучающей выборки еще можно было учить их и с нуля - с меньшей было бы совсем плохо.\n",
        "\n",
        "Поэтому стандартный пайплайн - скачать эмбеддинги, засунуть их в сеточку. Запустим его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZpY_Q1xZ18h",
        "outputId": "a5db2fc0-fe1f-4506-ca23-b673d6cdde41"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "w2v_model = api.load('glove-wiki-gigaword-100')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyHohi1GgXMr",
        "outputId": "824f825d-3946-4b8b-f220-cec56f5c4246"
      },
      "source": [
        "w2v_model.vectors.shape\n",
        "w2v_model.get_vector('is').shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYogOoKlgtcf"
      },
      "source": [
        "Построим подматрицу для слов из нашей тренировочной выборки:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6Pko77VjFQx",
        "outputId": "25031ae0-1d84-4178-96db-e3c8d313230a"
      },
      "source": [
        "w2v_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.KeyedVectors at 0x7f828585f050>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsCstxiO03oT",
        "outputId": "4ee14280-ae5a-48e2-fbd6-62a9b83a89e6"
      },
      "source": [
        "known_count = 0\n",
        "embeddings = np.zeros((len(word2ind), w2v_model.vectors.shape[1]))\n",
        "for word, ind in word2ind.items():\n",
        "    word = word.lower()\n",
        "    if word in w2v_model.key_to_index:\n",
        "        embeddings[ind] = w2v_model.get_vector(word)\n",
        "        known_count += 1\n",
        "        \n",
        "print('Know {} out of {} word embeddings'.format(known_count, len(word2ind)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Know 38736 out of 45441 word embeddings\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcG7i-R8hbY3"
      },
      "source": [
        "**Задание** Сделайте модель с предобученной матрицей. Используйте `nn.Embedding.from_pretrained`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-A9O54U8jaxf",
        "outputId": "afb7d89c-7a25-4695-a20a-794d487db271"
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(45441, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OMsebzNjSuX"
      },
      "source": [
        "embeddings_t = torch.from_numpy(embeddings)\n",
        "embeddings_t.requires_grad = True\n",
        "embeddings_t = embeddings_t.float().cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxaRBpQd0pat"
      },
      "source": [
        "class LSTMTaggerWithPretrainedEmbs(nn.Module):\n",
        "    def __init__(self, embeddings, tagset_size, lstm_hidden_dim=64, lstm_layers_count=1):\n",
        "        super().__init__()\n",
        "        \n",
        "        self._emb = nn.Embedding.from_pretrained(embeddings_t) # важно: по дефолту freeze=True, embeddings не обучаются!\n",
        "        self._lstm = nn.LSTM(embeddings_t.shape[1], \n",
        "                             lstm_hidden_dim, \n",
        "                             num_layers=lstm_layers_count, \n",
        "                             bidirectional = True)\n",
        "        self._out_layer = nn.Linear(2*lstm_hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        emb = self._emb(inputs)\n",
        "        output, _ = self._lstm(emb)\n",
        "        out = self._out_layer(output)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBtI6BDE-Fc7",
        "outputId": "8655f590-0840-4342-fbd5-7ecdecc2010f"
      },
      "source": [
        "model = LSTMTaggerWithPretrainedEmbs(\n",
        "    embeddings=embeddings,\n",
        "    tagset_size=len(tag2ind)\n",
        ").cuda()\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "fit(model, criterion, optimizer, train_data=(X_train, y_train), epochs_count=35,\n",
        "    batch_size=64, val_data=(X_val, y_val), val_batch_size=512)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1 / 35] Train: Loss = 42.76890, Accuracy = 79.92%: 100%|██████████| 572/572 [00:15<00:00, 36.99it/s]\n",
            "[1 / 35]   Val: Loss = 35.28130, Accuracy = 89.52%: 100%|██████████| 13/13 [00:00<00:00, 33.35it/s]\n",
            "[2 / 35] Train: Loss = 16.91721, Accuracy = 91.89%: 100%|██████████| 572/572 [00:15<00:00, 37.27it/s]\n",
            "[2 / 35]   Val: Loss = 25.15937, Accuracy = 92.29%: 100%|██████████| 13/13 [00:00<00:00, 33.53it/s]\n",
            "[3 / 35] Train: Loss = 12.54278, Accuracy = 93.78%: 100%|██████████| 572/572 [00:15<00:00, 38.13it/s]\n",
            "[3 / 35]   Val: Loss = 18.91427, Accuracy = 93.73%: 100%|██████████| 13/13 [00:00<00:00, 34.91it/s]\n",
            "[4 / 35] Train: Loss = 9.85814, Accuracy = 94.85%: 100%|██████████| 572/572 [00:15<00:00, 38.12it/s]\n",
            "[4 / 35]   Val: Loss = 16.98180, Accuracy = 94.53%: 100%|██████████| 13/13 [00:00<00:00, 35.39it/s]\n",
            "[5 / 35] Train: Loss = 8.32855, Accuracy = 95.52%: 100%|██████████| 572/572 [00:15<00:00, 37.25it/s]\n",
            "[5 / 35]   Val: Loss = 14.47994, Accuracy = 95.00%: 100%|██████████| 13/13 [00:00<00:00, 33.87it/s]\n",
            "[6 / 35] Train: Loss = 7.13231, Accuracy = 95.97%: 100%|██████████| 572/572 [00:15<00:00, 38.04it/s]\n",
            "[6 / 35]   Val: Loss = 13.18629, Accuracy = 95.41%: 100%|██████████| 13/13 [00:00<00:00, 35.60it/s]\n",
            "[7 / 35] Train: Loss = 6.34487, Accuracy = 96.31%: 100%|██████████| 572/572 [00:14<00:00, 38.38it/s]\n",
            "[7 / 35]   Val: Loss = 12.83894, Accuracy = 95.71%: 100%|██████████| 13/13 [00:00<00:00, 36.04it/s]\n",
            "[8 / 35] Train: Loss = 5.52015, Accuracy = 96.61%: 100%|██████████| 572/572 [00:15<00:00, 37.69it/s]\n",
            "[8 / 35]   Val: Loss = 11.92172, Accuracy = 95.81%: 100%|██████████| 13/13 [00:00<00:00, 33.55it/s]\n",
            "[9 / 35] Train: Loss = 5.03650, Accuracy = 96.83%: 100%|██████████| 572/572 [00:15<00:00, 37.39it/s]\n",
            "[9 / 35]   Val: Loss = 10.80454, Accuracy = 96.03%: 100%|██████████| 13/13 [00:00<00:00, 35.39it/s]\n",
            "[10 / 35] Train: Loss = 4.54112, Accuracy = 97.04%: 100%|██████████| 572/572 [00:15<00:00, 37.61it/s]\n",
            "[10 / 35]   Val: Loss = 11.31178, Accuracy = 96.11%: 100%|██████████| 13/13 [00:00<00:00, 34.39it/s]\n",
            "[11 / 35] Train: Loss = 4.16700, Accuracy = 97.18%: 100%|██████████| 572/572 [00:15<00:00, 37.05it/s]\n",
            "[11 / 35]   Val: Loss = 10.26857, Accuracy = 96.31%: 100%|██████████| 13/13 [00:00<00:00, 35.06it/s]\n",
            "[12 / 35] Train: Loss = 3.86666, Accuracy = 97.31%: 100%|██████████| 572/572 [00:15<00:00, 37.95it/s]\n",
            "[12 / 35]   Val: Loss = 11.33402, Accuracy = 96.32%: 100%|██████████| 13/13 [00:00<00:00, 34.21it/s]\n",
            "[13 / 35] Train: Loss = 3.59250, Accuracy = 97.44%: 100%|██████████| 572/572 [00:14<00:00, 38.75it/s]\n",
            "[13 / 35]   Val: Loss = 11.24074, Accuracy = 96.45%: 100%|██████████| 13/13 [00:00<00:00, 37.28it/s]\n",
            "[14 / 35] Train: Loss = 3.30422, Accuracy = 97.56%: 100%|██████████| 572/572 [00:15<00:00, 37.47it/s]\n",
            "[14 / 35]   Val: Loss = 10.88618, Accuracy = 96.45%: 100%|██████████| 13/13 [00:00<00:00, 34.17it/s]\n",
            "[15 / 35] Train: Loss = 3.12870, Accuracy = 97.66%: 100%|██████████| 572/572 [00:15<00:00, 37.61it/s]\n",
            "[15 / 35]   Val: Loss = 9.63042, Accuracy = 96.55%: 100%|██████████| 13/13 [00:00<00:00, 36.42it/s]\n",
            "[16 / 35] Train: Loss = 2.93031, Accuracy = 97.74%: 100%|██████████| 572/572 [00:14<00:00, 38.38it/s]\n",
            "[16 / 35]   Val: Loss = 10.18558, Accuracy = 96.51%: 100%|██████████| 13/13 [00:00<00:00, 35.36it/s]\n",
            "[17 / 35] Train: Loss = 2.72006, Accuracy = 97.85%: 100%|██████████| 572/572 [00:15<00:00, 38.08it/s]\n",
            "[17 / 35]   Val: Loss = 10.24596, Accuracy = 96.52%: 100%|██████████| 13/13 [00:00<00:00, 34.10it/s]\n",
            "[18 / 35] Train: Loss = 2.58963, Accuracy = 97.93%: 100%|██████████| 572/572 [00:15<00:00, 36.54it/s]\n",
            "[18 / 35]   Val: Loss = 8.90968, Accuracy = 96.58%: 100%|██████████| 13/13 [00:00<00:00, 33.62it/s]\n",
            "[19 / 35] Train: Loss = 2.46029, Accuracy = 97.99%: 100%|██████████| 572/572 [00:15<00:00, 36.96it/s]\n",
            "[19 / 35]   Val: Loss = 10.25926, Accuracy = 96.67%: 100%|██████████| 13/13 [00:00<00:00, 35.59it/s]\n",
            "[20 / 35] Train: Loss = 2.29794, Accuracy = 98.08%: 100%|██████████| 572/572 [00:15<00:00, 37.56it/s]\n",
            "[20 / 35]   Val: Loss = 10.47576, Accuracy = 96.70%: 100%|██████████| 13/13 [00:00<00:00, 33.04it/s]\n",
            "[21 / 35] Train: Loss = 2.20685, Accuracy = 98.14%: 100%|██████████| 572/572 [00:15<00:00, 38.05it/s]\n",
            "[21 / 35]   Val: Loss = 9.45592, Accuracy = 96.75%: 100%|██████████| 13/13 [00:00<00:00, 34.99it/s]\n",
            "[22 / 35] Train: Loss = 2.07402, Accuracy = 98.22%: 100%|██████████| 572/572 [00:15<00:00, 37.65it/s]\n",
            "[22 / 35]   Val: Loss = 10.32854, Accuracy = 96.78%: 100%|██████████| 13/13 [00:00<00:00, 35.28it/s]\n",
            "[23 / 35] Train: Loss = 1.99154, Accuracy = 98.27%: 100%|██████████| 572/572 [00:14<00:00, 38.54it/s]\n",
            "[23 / 35]   Val: Loss = 8.60891, Accuracy = 96.74%: 100%|██████████| 13/13 [00:00<00:00, 34.74it/s]\n",
            "[24 / 35] Train: Loss = 1.87851, Accuracy = 98.32%: 100%|██████████| 572/572 [00:15<00:00, 36.49it/s]\n",
            "[24 / 35]   Val: Loss = 9.10361, Accuracy = 96.79%: 100%|██████████| 13/13 [00:00<00:00, 33.28it/s]\n",
            "[25 / 35] Train: Loss = 1.78113, Accuracy = 98.41%: 100%|██████████| 572/572 [00:15<00:00, 36.88it/s]\n",
            "[25 / 35]   Val: Loss = 9.53620, Accuracy = 96.78%: 100%|██████████| 13/13 [00:00<00:00, 33.59it/s]\n",
            "[26 / 35] Train: Loss = 1.70533, Accuracy = 98.46%: 100%|██████████| 572/572 [00:15<00:00, 36.55it/s]\n",
            "[26 / 35]   Val: Loss = 10.96571, Accuracy = 96.75%: 100%|██████████| 13/13 [00:00<00:00, 31.83it/s]\n",
            "[27 / 35] Train: Loss = 1.72525, Accuracy = 98.23%:  53%|█████▎    | 301/572 [00:08<00:07, 35.85it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ne_8f24h8kg"
      },
      "source": [
        "**Задание** Оцените качество модели на тестовой выборке. Обратите внимание, вовсе не обязательно ограничиваться векторами из урезанной матрицы - вполне могут найтись слова в тесте, которых не было в трейне и для которых есть эмбеддинги.\n",
        "\n",
        "Добейтесь качества лучше прошлых моделей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPUuAPGhEGVR",
        "outputId": "8133867c-bba1-443c-ddb7-7a0d5462b839"
      },
      "source": [
        "test_ac =  compute_accuracy(model, (X_test, y_test))\n",
        "print(f'Test accuracy is {test_ac:.2%}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is 96.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTjnRRF42lJH"
      },
      "source": [
        "### Сравнение результатов работы разных подходов\n",
        "| №      | Название        | Точность\n",
        "| :---:  |:-------------:  | :------------------ | \n",
        "| 1      | Unigram Tagger  | 92.62%              | \n",
        "| 2      | Bigram Tagger   | 93.42%              | \n",
        "| 3      | Trigram Tagger  | 93.28%              | \n",
        "| 4      | LSTM            | 94.02%              | \n",
        "| 5      | BiLSTM          | 95.42%              | \n",
        "| 6      | BiLSTM Pretrained embeddings| 96.82%  |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A7Km9BYmAgC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}